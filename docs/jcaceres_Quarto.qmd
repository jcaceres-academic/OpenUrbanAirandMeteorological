---
title: "Citizen Science and STEM Education with R: Teaching Innovation through Open Urban Climate Data"
subtitle: "Open Data Analysis from Madrid (2023)"
author:
  - name: "Jesús Cáceres Tello"
    affiliation: "Department of Computer Systems and Computing, Universidad Complutense de Madrid"
    email: "jescacer@ucm.es"
  - name: "José Javier Galán Hernández"
    affiliation: "Department of Computer Science, Universidad de Alcalá"
    email: "jose.galan@uah.es"
format:
  html:
    theme: cosmo
    toc: true
    toc-title: "Contents"
    toc-location: left
    page-layout: full
engine: knitr
editor: visual
execute:
  echo: false
  warning: false
  message: false
title-block-style: plain
title-block-banner: false
---

## 1. Introduction

The availability of open environmental datasets published by the Madrid City Council provides an exceptional opportunity to teach and learn data analysis using real-world urban data.\
This notebook integrates **air quality** and **meteorological** records from the city’s open data portal and demonstrates how R can be used to clean, analyse, and visualise environmental information in a fully reproducible workflow.

The goal is twofold:\
1. To promote data literacy and scientific reasoning through real datasets.\
2. To create an educational resource that connects data science with urban sustainability challenges.

## 2. Data Sources

The analysis uses three open datasets published by the **Madrid City Council** (Portal de Datos Abiertos: <https://datos.madrid.es/portal/site/egob>), covering the period **2020–2024**:

1.  **Air Quality:** hourly concentrations of major pollutants (NO₂, O₃, PM₁₀, PM₂.₅, SO₂, CO, BTX).\
2.  **Meteorological Data:** daily temperature, humidity, precipitation, and wind speed.\
3.  **Station Metadata:** geolocation, altitude, and classification (*Urban traffic*, *Urban background*, *Suburban*).

For this case study, the year **2023** was selected to ensure completeness and comparability across datasets.

## 3. Data Processing

Key R packages for the workflow include `dplyr`, `tidyr`, `ggplot2`, and `lubridate`.\
The datasets are harmonised by date and station, creating daily mean values for each pollutant.

```{r}
# ===============================
# 1️ LIBRARIES
# ===============================
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)

# ===============================
# 2 LOAD AND COMBINE CSV FILES
# ===============================

# Folder containing monthly CSV files (January–December 2023)
ruta <- "Calidad del Aire/2023"

# List all CSV files in the directory
archivos <- list.files(ruta, pattern = "\\.csv$", full.names = TRUE)

# Read and merge all monthly files into a single dataframe
aire <- do.call(bind_rows, lapply(archivos, function(f) {
  read.csv(f, sep = ";", stringsAsFactors = FALSE)
}))

# ===============================
# 3️ CREATE DATE COLUMN
# ===============================
# Combine year, month, and day columns into a single Date object
# Ensure correct column names: ANO, MES, DIA
aire$fecha <- as.Date(
  paste(aire$ANO, aire$MES, aire$DIA, sep = "-"),
  format = "%Y-%m-%d"
)

# Quick check: first few rows
head(aire[, c("ANO", "MES", "DIA", "fecha")])
```

## 4. Temporal Evolution of NO₂ and O₃

The figure below shows the daily mean concentrations of nitrogen dioxide (NO₂) and ozone (O₃) for 2023.\
These pollutants exhibit opposite seasonal behaviour: NO₂ peaks during winter due to traffic and heating emissions, while O₃ increases in summer as a photochemical secondary pollutant.

```{r}

aire_long <- aire %>% pivot_longer(cols = starts_with("H"), names_to = "hour", values_to = "value") %>% group_by(ANO, MES, DIA, MAGNITUD) %>% summarise(mean_day = mean(value, na.rm = TRUE)) %>% ungroup()

# Preparamos los datos
plot_data <- aire_long %>%
  filter(MAGNITUD %in% c(8, 14)) %>%
  mutate(
    date = as.Date(paste(ANO, MES, DIA, sep = "-")),
    pollutant = ifelse(MAGNITUD == 8, "NO2", "O3")
  )

# Gráfico de evolución diaria
ggplot(plot_data, aes(x = date, y = mean_day, colour = pollutant)) +
  geom_line(linewidth = 0.7) +
  scale_colour_manual(
    values = c("NO2" = "steelblue", "O3" = "orange"),
    labels = c(expression(NO[2]), expression(O[3]))
  ) +
  labs(
    title = expression(bold("Daily evolution of NO"[2]*" and O"[3]*" — Madrid (2023)")),
    x = "Date",
    y = expression(paste("Concentration (", mu, "g/m"^3, ")")),
    colour = "Pollutant"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold", size = 15),
    legend.title = element_text(face = "bold")
  )

```

The figure illustrates the daily evolution of nitrogen dioxide (NO₂) and ozone (O₃) concentrations during 2023 in Madrid. The two pollutants show opposite seasonal behaviour: NO₂ peaks during winter months, mainly due to road traffic and atmospheric stability, while O₃ increases during spring and summer, when photochemical activity is higher. This complementary pattern offers an excellent opportunity for students to explore data correlations and interpret air-quality dynamics using R.

```{r, echo=FALSE}
# ===============================
# SUMMARY TABLE OF POLLUTANTS
# ===============================

# 1️⃣ Calcular las estadísticas resumidas
aire_summary <- plot_data %>%
  group_by(pollutant) %>%
  summarise(
    mean_conc = mean(mean_day, na.rm = TRUE),
    sd_conc   = sd(mean_day, na.rm = TRUE),
    max_conc  = max(mean_day, na.rm = TRUE)
  )

# 2️⃣ Formatear y centrar la tabla (usa kableExtra)
library(knitr)
library(kableExtra)

aire_summary %>%
  mutate(
    mean_conc = sprintf("%.2f", mean_conc),
    sd_conc   = sprintf("%.2f", sd_conc),
    max_conc  = sprintf("%.2f", max_conc)
  ) %>%
  kable(
    caption = "Summary statistics for NO₂ and O₃ (2023)",
    align = "c"
  ) %>%
  kable_styling(
    full_width = FALSE,
    position = "center",
    font_size = 14,
    bootstrap_options = c("striped", "hover", "condensed")
  )


```

These results demonstrate how open environmental datasets can be used in R to develop students’ analytical, interpretive, and communication skills — bridging data science education with urban sustainability and public health.

## 5. Contrasting Seasonal Patterns: NO₂ vs O₃

Understanding the joint dynamics of nitrogen dioxide (NO₂) and ozone (O₃) provides valuable insight into the chemical and meteorological mechanisms that shape urban air quality.

While NO₂ is mainly a **primary pollutant** emitted by traffic and heating, O₃ is a **secondary photochemical compound** formed through reactions between NOₓ and volatile organic compounds under sunlight.\
This leads to **opposite seasonal behaviours**: NO₂ concentrations peak in winter due to stable atmospheric conditions, whereas O₃ increases in spring and summer.

The following comparative panel summarises these relationships, showing daily mean concentrations for both pollutants in 2023.

```{r}
# =====================================================
# Forecast of NO₂ concentrations — Madrid (2023–2024)
# Improved fit + full legend + subscript fix
# =====================================================

library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(prophet)

# 1️⃣ Serie diaria robusta
no2_daily <- aire %>%
  filter(MAGNITUD == 8) %>%  # NO₂
  mutate(date = as.Date(sprintf("%04d-%02d-%02d", ANO, MES, DIA))) %>%
  pivot_longer(matches("^H\\d{2}$"), names_to = "hour", values_to = "value") %>%
  group_by(date) %>%
  summarise(no2 = median(value, na.rm = TRUE), .groups = "drop") %>%
  arrange(date)

# 2️⃣ Winsorización (control de valores extremos)
qs <- quantile(no2_daily$no2, probs = c(0.01, 0.99), na.rm = TRUE)
no2_daily <- no2_daily %>%
  mutate(no2 = pmin(pmax(no2, qs[1]), qs[2]))

# 3️⃣ Fechas coherentes (UTC)
no2_daily$date <- as.POSIXct(no2_daily$date, tz = "UTC")

# 4️⃣ Train/Test (últimos 30 días de 2023 para validación)
cutoff <- max(no2_daily$date) - days(30)
train  <- no2_daily %>% filter(date <= cutoff)
test   <- no2_daily %>% filter(date >  cutoff)

# 5️⃣ Prophet con mayor flexibilidad y estacionalidad diaria
df_train <- train %>% transmute(ds = date, y = no2)
m <- prophet(
  df_train,
  yearly.seasonality = TRUE,
  weekly.seasonality = TRUE,
  daily.seasonality  = TRUE,         # activa patrón semanal/día
  changepoint.prior.scale = 0.3      # curva más sensible a cambios
)

# 6️⃣ Predicción extendida hasta 2024 (+90 días)
horizon <- nrow(test) + 90
future  <- make_future_dataframe(m, periods = horizon)
fcst    <- predict(m, future)

# 7️⃣ Métricas (MAE, RMSE)
pred_test <- fcst %>%
  select(ds, yhat) %>%
  right_join(test %>% transmute(ds = date, y = no2), by = "ds") %>%
  mutate(abs_err = abs(y - yhat), sq_err = (y - yhat)^2)

MAE  <- mean(pred_test$abs_err, na.rm = TRUE)
RMSE <- sqrt(mean(pred_test$sq_err, na.rm = TRUE))

# 8️⃣ Gráfico mejorado
last_train <- max(train$date)

p <- ggplot() +
  # Banda de confianza (zona gris)
  geom_ribbon(
    data = fcst %>% filter(as.POSIXct(ds, tz = "UTC") > last_train),
    aes(x = ds, ymin = yhat_lower, ymax = yhat_upper, fill = "Confidence interval"),
    alpha = 0.4
  ) +
  # Curva de forecast
  geom_line(
    data = fcst,
    aes(x = ds, y = yhat, colour = "Forecast"),
    linewidth = 1.1
  ) +
  # Curva observada
  geom_line(
    data = no2_daily,
    aes(x = date, y = no2, colour = "Observed"),
    linewidth = 0.9
  ) +
  scale_colour_manual(
    name   = "Series",
    values = c("Observed" = "steelblue", "Forecast" = "orange")
  ) +
  scale_fill_manual(
    name = "",
    values = c("Confidence interval" = "grey80")
  ) +
  labs(
    title = expression("Forecast of NO"[2] * " concentrations — Madrid (2023–2024)"),
    x = "Date",
    y = expression(paste("Concentration (", mu, "g/m"^3, ")")),
    caption = sprintf("Prophet model | Hold-out: last 30 days of 2023 | MAE %.1f, RMSE %.1f µg/m³",
                      MAE, RMSE)
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title   = element_text(face = "bold", size = 16),
    legend.title = element_text(face = "bold"),
    legend.position = "top",
    legend.box = "vertical",
    plot.caption = element_text(size = 9, colour = "grey40"),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(size = 0.3)
  )

p
# ggsave("Forecast_NO2_Madrid_Final.png", p, width = 9, height = 4.5, dpi = 300)



```

## 6. Integrating Meteorological Data

This section demonstrates how meteorological variables are processed and linked
to air-quality observations using R. Hourly records from the Madrid Open Data Portal
are reshaped, validated, and aggregated into daily means before being joined with
NO₂ and O₃ concentrations.

```{r}
# Load and harmonise meteorological data
library(dplyr)
library(tidyr)
library(lubridate)

met_raw <- read_csv("data/meteorology_2020_2024.csv")

met_clean <- met_raw |>
  pivot_longer(starts_with("H"), names_to = "hour", values_to = "value") |>
  filter(V == "V") |>
  group_by(STATION, DATE) |>
  summarise(
    T = mean(TEMP, na.rm = TRUE),
    RH = mean(HUMIDITY, na.rm = TRUE),
    WS = mean(WIND_SPEED, na.rm = TRUE),
    WD = circular::mean.circular(WIND_DIR),
    SR = mean(SOLAR_RAD, na.rm = TRUE),
    P  = sum(PRECIP, na.rm = TRUE)
  )

# Merge with air-quality data
full_data <- left_join(air_quality_daily, met_clean, by = c("STATION", "DATE"))
```


## 7. Conclusion and Outlook

This notebook demonstrates a reproducible workflow for analysing open air-quality data with R.\
Future extensions will include the integration of meteorological predictors and time-series forecasting models, enabling students to explore predictive analytics and climate–pollution interactions.
